{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5773bc85",
   "metadata": {},
   "source": [
    "<style  type=\"text/css\">\n",
    "cool {\n",
    "  width: 100px;\n",
    "  height: 100px;\n",
    "  background-color: red;\n",
    "  position: relative;\n",
    "  -webkit-animation-name: example; /* Safari 4.0 - 8.0 */\n",
    "  -webkit-animation-duration: 4s; /* Safari 4.0 - 8.0 */\n",
    "  -webkit-animation-iteration-count: infinite; /* Safari 4.0 - 8.0 */\n",
    "  animation-name: example;\n",
    "  animation-duration: 4s;\n",
    "  animation-iteration-count: infinite;\n",
    "}\n",
    "\n",
    "loud {\n",
    "    font-size: 20pt;\n",
    "    }\n",
    "\n",
    "/* Safari 4.0 - 8.0 */\n",
    "@-webkit-keyframes example {\n",
    "  0%   {background-color:red; left:0px; top:0px;}\n",
    "  25%  {background-color:yellow; left:200px; top:0px;}\n",
    "  50%  {background-color:blue; left:200px; top:200px;}\n",
    "  75%  {background-color:green; left:0px; top:200px;}\n",
    "  100% {background-color:red; left:0px; top:0px;}\n",
    "}\n",
    "\n",
    "/* Standard syntax */\n",
    "@keyframes example {\n",
    "  0%   {background-color:red; left:0px; top:0px;}\n",
    "  25%  {background-color:yellow; left:200px; top:0px;}\n",
    "  50%  {background-color:blue; left:200px; top:200px;}\n",
    "  75%  {background-color:green; left:0px; top:200px;}\n",
    "  100% {background-color:red; left:0px; top:0px;}\n",
    "}\n",
    "</style>\n",
    "\n",
    "<b><center>\n",
    "<span style=\"font-size: 24pt; line-height: 1.2\">\n",
    "COMS W4111: Introduction to Databases<br>\n",
    "Spring 2024, Sections 002/V02\n",
    "</span>\n",
    "</center></b>\n",
    "<br>\n",
    "<p>\n",
    "<i><center>\n",
    "<span style=\"font-size: 20pt; line-height: 1.2\">\n",
    "Homework 4<br>\n",
    "</span>\n",
    "</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3fc98",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- This notebook contains HW4. **Both Programming and Nonprogramming tracks should complete this homework.**\n",
    "- You will submit **PDF and ZIP files** for this assignment. Gradescope will have two separate assignments for these.\n",
    "- For the PDF:\n",
    "    - The most reliable way to save as PDF is to go to your browser's menu bar and click `File -> Print`. Switch the orientation to landscape mode, and hit save.\n",
    "    - **MAKE SURE ALL YOUR WORK (CODE AND SCREENSHOTS) IS VISIBLE ON THE PDF. YOU WILL NOT GET CREDIT IF ANYTHING IS CUT OFF.** Reach out for troubleshooting.\n",
    "    - **MAKE SURE YOU DON'T SUBMIT A SINGLE PAGE PDF.** Your PDF should have multiple pages.\n",
    "- For the ZIP:\n",
    "    - Zip a folder containing this notebook and any screenshots.\n",
    "    - You may delete any unnecessary files, such as caches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487c2b6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e56fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/pymysql/connections.py\", line 644, in connect\n",
      "    sock = socket.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/socket.py\", line 851, in create_connection\n",
      "    raise exceptions[0]\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/socket.py\", line 836, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 145, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 3293, in raw_connection\n",
      "    return self.pool.connect()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 452, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 1269, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 716, in checkout\n",
      "    rec = pool._do_get()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/impl.py\", line 169, in _do_get\n",
      "    with util.safe_reraise():\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/impl.py\", line 167, in _do_get\n",
      "    return self._create_connection()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 393, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 678, in __init__\n",
      "    self.__connect()\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 902, in __connect\n",
      "    with util.safe_reraise():\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 898, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/create.py\", line 645, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/default.py\", line 616, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/pymysql/connections.py\", line 358, in __init__\n",
      "    self.connect()\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/pymysql/connections.py\", line 711, in connect\n",
      "    raise exc\n",
      "pymysql.err.OperationalError: (2003, \"Can't connect to MySQL server on 'localhost' ([Errno 61] Connection refused)\")\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sql/magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sql/connection.py\", line 70, in set\n",
      "    cls.current = existing or Connection(descriptor, connect_args, creator)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sql/connection.py\", line 55, in __init__\n",
      "    self.internal_connection = engine.connect()\n",
      "                               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 3269, in connect\n",
      "    return self._connection_cls(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 147, in __init__\n",
      "    Connection._handle_dbapi_exception_noconnection(\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 2431, in _handle_dbapi_exception_noconnection\n",
      "    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 145, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 3293, in raw_connection\n",
      "    return self.pool.connect()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 452, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 1269, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 716, in checkout\n",
      "    rec = pool._do_get()\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/impl.py\", line 169, in _do_get\n",
      "    with util.safe_reraise():\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/impl.py\", line 167, in _do_get\n",
      "    return self._create_connection()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 393, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 678, in __init__\n",
      "    self.__connect()\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 902, in __connect\n",
      "    with util.safe_reraise():\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/pool/base.py\", line 898, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/create.py\", line 645, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/default.py\", line 616, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/pymysql/connections.py\", line 358, in __init__\n",
      "    self.connect()\n",
      "  File \"/Users/darthvaper/anaconda3/lib/python3.11/site-packages/pymysql/connections.py\", line 711, in connect\n",
      "    raise exc\n",
      "sqlalchemy.exc.OperationalError: (pymysql.err.OperationalError) (2003, \"Can't connect to MySQL server on 'localhost' ([Errno 61] Connection refused)\")\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql mysql+pymysql://root:dbuserdbuser@localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a7e3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Obtaining dependency information for pymongo from https://files.pythonhosted.org/packages/2b/f0/bc30f0d9f7f1b3de1eb51ef8ed85378ff237f551c28bf4a23e71cf92aa20/pymongo-4.6.3-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading pymongo-4.6.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Obtaining dependency information for dnspython<3.0.0,>=1.16.0 from https://files.pythonhosted.org/packages/87/a1/8c5287991ddb8d3e4662f71356d9656d91ab3a36618c3dd11b280df0d255/dnspython-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading pymongo-4.6.3-cp311-cp311-macosx_10_9_universal2.whl (534 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m534.5/534.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.6.1 pymongo-4.6.3\n",
      "Collecting neo4j\n",
      "  Downloading neo4j-5.19.0.tar.gz (202 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz in /Users/darthvaper/anaconda3/lib/python3.11/site-packages (from neo4j) (2023.3.post1)\n",
      "Building wheels for collected packages: neo4j\n",
      "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neo4j: filename=neo4j-5.19.0-py3-none-any.whl size=280741 sha256=bdf15f7e1605cebf27a952cf18ece8ecf21fcf735745b74d7f972819c385a388\n",
      "  Stored in directory: /Users/darthvaper/Library/Caches/pip/wheels/48/0d/71/a6d5ad9ecdd1cb0fae2aeea918a9bed3d8120ded12b3cfa8ed\n",
      "Successfully built neo4j\n",
      "Installing collected packages: neo4j\n",
      "Successfully installed neo4j-5.19.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pymongo\n",
    "!{sys.executable} -m pip install --upgrade neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648dce6",
   "metadata": {},
   "source": [
    "- If you get warnings below, try restarting your kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab5da77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "Empty host (or extra comma in host list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# TODO: Fill in with your Mongo URL\u001b[39;00m\n\u001b[1;32m      6\u001b[0m mongo_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m mongo_client \u001b[38;5;241m=\u001b[39m pymongo\u001b[38;5;241m.\u001b[39mMongoClient(mongo_url)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# TODO: Fill in with your Neo4j credentials\u001b[39;00m\n\u001b[1;32m     10\u001b[0m neo4j_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/mongo_client.py:788\u001b[0m, in \u001b[0;36mMongoClient.__init__\u001b[0;34m(self, host, port, document_class, tz_aware, connect, type_registry, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m         fqdn \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfqdn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 788\u001b[0m         seeds\u001b[38;5;241m.\u001b[39mupdate(uri_parser\u001b[38;5;241m.\u001b[39msplit_hosts(entity, port))\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seeds:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to specify at least one host\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymongo/uri_parser.py:386\u001b[0m, in \u001b[0;36msplit_hosts\u001b[0;34m(hosts, default_port)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m hosts\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m entity:\n\u001b[0;32m--> 386\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty host (or extra comma in host list).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    387\u001b[0m     port \u001b[38;5;241m=\u001b[39m default_port\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Unix socket entities don't have ports\u001b[39;00m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: Empty host (or extra comma in host list)."
     ]
    }
   ],
   "source": [
    "import neo4j\n",
    "import pandas\n",
    "import pymongo\n",
    "\n",
    "# TODO: Fill in with your Mongo URL\n",
    "mongo_url = \"\"\n",
    "mongo_client = pymongo.MongoClient(mongo_url)\n",
    "\n",
    "# TODO: Fill in with your Neo4j credentials\n",
    "neo4j_url = \"\"\n",
    "neo4j_password = \"\"\n",
    "# username is always \"neo4j\"\n",
    "graph = neo4j.GraphDatabase.driver(neo4j_url, auth=(\"neo4j\", neo4j_password))\n",
    "graph.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be6c99",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a5db3",
   "metadata": {},
   "source": [
    "# Written Questions\n",
    "\n",
    "- As usual, do not bloviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd164cc5",
   "metadata": {},
   "source": [
    "## W1\n",
    "\n",
    "Explain the following concepts:\n",
    "\n",
    "1. Clustering index\n",
    "2. Nonclustering index\n",
    "3. Sparse index\n",
    "4. Dense index\n",
    "\n",
    "\n",
    "Clustering Index: Organizes the actual data records in the database based on the key values of the index, efficient for range queries, but insertion and deletion can be costly because they may require reorganizing the data.\n",
    "\n",
    "Nonclustering Index: Contains index entries that point to the actual data records, which are stored separately, multiple nonclustering indexes can exist on a table, but may lead to slower range queries compared to clustering indexes.\n",
    "\n",
    "Sparse Index: Only index entries for some of the records based on a certain interval, requires less space, can be slower for lookups since it might need to scan through more data compared to a dense index.\n",
    "\n",
    "Dense Index: Contains an index entry for every single record in the database, faster lookups for any given record, but takes up more space than a sparse index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ea2a8",
   "metadata": {},
   "source": [
    "## W2\n",
    "\n",
    "Explain why nonclustering indexes must be dense.\n",
    "\n",
    "Nonclustering indexes must be dense to ensure that every record in the table can be efficiently located. Since the data records are stored separately from the index and not in sorted order, a dense index—with an entry for every record—guarantees that any search or lookup can directly access the corresponding record without missing any, ensuring comprehensive and efficient data retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cdac86",
   "metadata": {},
   "source": [
    "## W3\n",
    "\n",
    "Suppose that, in a table containing information about Columbia classes, the columns `class_code`, `semester`, and `year` are queried frequently **individually**. Would putting a composite index on `(class_code, semester, year)` be a good idea? Why or why not?\n",
    "\n",
    "\n",
    "No, putting a composite index on (class_code, semester, year) would not be the best idea if the columns are queried frequently individually. A composite index is most effective when queries involve all the columns in the index or the leftmost subset. Queries on individual columns won't benefit optimally from a composite index structured this way, because the index's effectiveness diminishes when the query does not start with the first column in the composite index sequence. It would be more beneficial to create separate indexes on each column to optimize their individual query performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646005a0",
   "metadata": {},
   "source": [
    "## W4\n",
    "\n",
    "Explain the following concepts:\n",
    "\n",
    "1. Hash index\n",
    "2. B+ tree index\n",
    "\n",
    "Hash Index: buckets store entries with pointers to records, ideal for quick lookups of specific items, Best for exact match searches, but not suited for range queries or maintaining order.\n",
    "B+ Tree Index: Tree-based structure with nodes; optimizes reading/writing large blocks of sorted data, supports a wide range of queries, including point, range, and sequential access, efficient for operations involving large data sets, maintaining order, and facilitating quick inserts and deletes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd1854",
   "metadata": {},
   "source": [
    "## W5\n",
    "\n",
    "Give one advantage and one disadvantage of hash indexes compared to B+ tree indexes.\n",
    "\n",
    "\n",
    "Advantage of Hash Indexes: Faster data retrieval for exact-match queries due to direct computation.\n",
    "\n",
    "Disadvantage of Hash Indexes: Inefficient for range queries, as they do not maintain any sort of order among keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b968a",
   "metadata": {},
   "source": [
    "## W6\n",
    "\n",
    "Explain the role of the buffer in a DBMS. Why doesn't the DBMS simply load the entire database in its buffer?\n",
    "\n",
    "\n",
    "The buffer in a DBMS temporarily holds data from the disk to reduce the number of disk I/O operations, speeding up read/write operations since accessing data in memory is much faster than disk access. A DBMS doesn't load the entire database into its buffer due to limitations in physical memory size and the inefficiency of loading data that might not be needed immediately or frequently, which would waste valuable memory resources and potentially slow down the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244e0a1",
   "metadata": {},
   "source": [
    "## W7\n",
    "\n",
    "Explain the following concepts as they relate to buffer replacement policies:\n",
    "\n",
    "1. Clairvoyant algorithm\n",
    "2. Least recently used strategy\n",
    "3. Most recently used strategy\n",
    "4. Clock algorithm\n",
    "\n",
    "\n",
    "Clairvoyant Algorithm: An ideal, theoretical approach that always evicts the page that will be used farthest in the future. It requires future knowledge of requests, serving as a benchmark for other algorithms' performance.\n",
    "\n",
    "Least Recently Used (LRU) Strategy: Evicts the page that has been unused for the longest time, based on the assumption that pages used recently will likely be used again soon.\n",
    "\n",
    "Most Recently Used (MRU) Strategy: Opposite of LRU, it evicts the most recently used page, based on the premise that the most recently accessed page will be the least likely to be accessed again in the near future.\n",
    "\n",
    "Clock Algorithm: A practical approximation of LRU that organizes pages in a circular manner (like a clock) and uses a \"hand\" that points to the oldest page. Pages are given a second chance before eviction if they are marked as recently used, efficiently managing memory with lower overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31276a5c",
   "metadata": {},
   "source": [
    "## W8\n",
    "\n",
    "NoSQL databases have become increasingly popular for applications. List 3 benefits of using NoSQL databases over SQL ones.\n",
    "\n",
    "\n",
    "Scalability: NoSQL databases are designed to scale out using distributed architectures, making them well-suited for handling large volumes of data and traffic.\n",
    "\n",
    "Flexibility: They often support schema-less data models, allowing for the storage of unstructured or semi-structured data without a predefined schema, which is beneficial for rapidly evolving applications.\n",
    "\n",
    "Performance: NoSQL databases can provide faster data retrieval and handling for specific types of queries and data models, particularly when dealing with large volumes of data that don't fit well into relational models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc01ff",
   "metadata": {},
   "source": [
    "## W9\n",
    "\n",
    "Explain the concept between impedance mismatch and how it relates to SQL vs. NoSQL databases.\n",
    "\n",
    "\n",
    "Impedance mismatch refers to the conflict between the object-oriented model used in application programming and the relational model used in SQL databases. This discrepancy arises because objects in code do not neatly map onto the tabular structure of relational databases, requiring additional effort to translate between the two models (e.g., using Object-Relational Mapping (ORM) tools). NoSQL databases, with their more flexible data models (such as document, key-value, graph), often align more closely with the object-oriented approach, reducing or eliminating the impedance mismatch and simplifying the interaction between application code and the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f625a83",
   "metadata": {},
   "source": [
    "## W10\n",
    "\n",
    "The relationship between students and courses is many-to-many. Due to its emphasis on atomicity, modeling this relationship in a relational database would require an associative entity. Explain how this relationship could be modeled in\n",
    "\n",
    "1. A document database, such as MongoDB\n",
    "2. A graph database, such as Neo4j\n",
    "\n",
    "\n",
    "In MongoDB (Document Database): This many-to-many relationship can be modeled using embedded documents or references. For instance, each Student document could contain an array of references (IDs) to Course documents they are enrolled in, or vice versa. \n",
    "\n",
    "In Neo4j (Graph Database): The relationship is naturally modeled by creating Student and Course nodes, with edges (relationships) connecting them. Each edge can represent an enrollment, directly mapping the many-to-many relationship. Additional properties can be added to these edges (such as enrollment date) to capture more details about the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75317a5",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13f0e4",
   "metadata": {},
   "source": [
    "# MongoDB\n",
    "\n",
    "- The cell below creates a database `w4111`, then a collection `episodes` inside `w4111`. It then inserts GoT episode data into the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563211a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mongo_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisodes.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 6\u001b[0m episodes \u001b[38;5;241m=\u001b[39m mongo_client[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw4111\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisodes\u001b[39m\u001b[38;5;124m\"\u001b[39m]    \n\u001b[1;32m      7\u001b[0m episodes\u001b[38;5;241m.\u001b[39mdrop()\n\u001b[1;32m      8\u001b[0m episodes\u001b[38;5;241m.\u001b[39minsert_many(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mongo_client' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"episodes.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "episodes = mongo_client[\"w4111\"][\"episodes\"]    \n",
    "episodes.drop()\n",
    "episodes.insert_many(data)\n",
    "print(\"Successfully inserted episode data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb5e2d",
   "metadata": {},
   "source": [
    "## M1\n",
    "\n",
    "- Write and execute a query that shows episodes and the number of scenes they contain\n",
    "- Your aggregation should have the following attributes:\n",
    "    - `episodeTitle`\n",
    "    - `seasonNum`\n",
    "    - `episodeNum`\n",
    "    - `numScenes`, which is the length of the episode's `scenes` array\n",
    "- Order your output on `numScenes` descending, and only keep episodes with more than 100 scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4173d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = episodes.aggregate(\n",
    "    # TODO: Put your query here\n",
    ")\n",
    "\n",
    "pandas.DataFrame(list(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69e2e8",
   "metadata": {},
   "source": [
    "## M2\n",
    "\n",
    "- Write and execute a query that shows the first three episodes for each season\n",
    "- Your aggregation should have the following attributes:\n",
    "    - `seasonNum`\n",
    "    - `firstThreeEpisodes`, which is an array that contains the titles of the first, second, and third episodes (in that order) of the season\n",
    "- Order your output on `seasonNum` ascending\n",
    "    - It's okay if the `firstThreeEpisodes` column is a bit truncated by the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcfcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = episodes.aggregate(\n",
    "    # TODO: Put your query here\n",
    ")\n",
    "\n",
    "pandas.DataFrame(list(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065799a6",
   "metadata": {},
   "source": [
    "## M3\n",
    "\n",
    "- Write and execute a query that shows statistics about each season\n",
    "- Your aggregation should have the following attributes:\n",
    "    - `seasonNum`\n",
    "    - `numEpisodes`, which is the number of episodes in the season\n",
    "    - `startDate`, which is the earliest air date associated with an episode in the season\n",
    "    - `endDate`, which is the latest air date associated with an episode in the season\n",
    "    - `shortestEpisodeLength`\n",
    "    - `longestEpisodeLength`\n",
    "        - The length of an episode is the greatest `sceneEnd` value in the episode's `scenes` array\n",
    "- Order your output on `seasonNum` ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = episodes.aggregate(\n",
    "    # TODO: Put your query here\n",
    ")\n",
    "\n",
    "pandas.DataFrame(list(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79a4f3",
   "metadata": {},
   "source": [
    "## M4\n",
    "\n",
    "- Write and execute a query that shows sublocations and the scenes they appear in\n",
    "- Your aggregation should have the following attributes:\n",
    "    - `subLocation`\n",
    "    - `totalScenes`, which is the number of scenes that are set in the sublocation\n",
    "    - `firstSeasonNum`\n",
    "    - `firstEpisodeNum`\n",
    "        - `(firstSeasonNum, firstEpisodeNum)` identifies the first episode that the sublocation appears in\n",
    "    - `lastSeasonNum`\n",
    "    - `lastEpisodeNum`\n",
    "        - `(lastSeasonNum, lastEpisodeNum)` identifies the last episode that the sublocation appears in\n",
    "- Order your output on `totalScenes` descending, and only keep the sublocations with more than 50 scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32790f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = episodes.aggregate(\n",
    "    # TODO: Put your query here\n",
    ")\n",
    "\n",
    "pandas.DataFrame(list(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120bab19",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3cd0a7",
   "metadata": {},
   "source": [
    "# Neo4j\n",
    "\n",
    "- The cell below creates nodes and relationships that model movies and the people involved in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movies.txt\") as f:\n",
    "    queries = str(f.read())\n",
    "\n",
    "graph.execute_query(\"match (p:Person), (m:Movie) detach delete p, m\")\n",
    "graph.execute_query(queries)\n",
    "print(\"Successfully inserted movie data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b403348",
   "metadata": {},
   "source": [
    "## N1\n",
    "\n",
    "- Write and execute a cypher that shows actors and the number of movies they appear in\n",
    "    - You should focus only on the `ACTED_IN` relationship, no other relationship\n",
    "- Your output should have the following attributes:\n",
    "    - `name`, which is the name of the actor\n",
    "    - `num_movies`\n",
    "- Order your output on `num_movies` descending, and only keep actors who have acted in 4 or more movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = graph.execute_query(\"\"\"\n",
    "    TODO: Put your query here\n",
    "\"\"\")\n",
    "\n",
    "pandas.DataFrame([dict(r) for r in res.records])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8134e83c",
   "metadata": {},
   "source": [
    "## N2\n",
    "\n",
    "- Write and execute a cypher that shows people and movies they either acted in or directed\n",
    "- Your output should have the following attributes:\n",
    "    - `name`, which is the name of the person\n",
    "    - `directed_movies`, which is an array of titles of movies that the person directed\n",
    "    - `acted_in_movies`, which is an array of titles of movies that the person acted in\n",
    "- Order your output on `name` ascending, and only keep people that have directed at least one movie **and** acted in at least one movie (i.e., there should be no empty arrays. Arrays with one element are fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7969df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = graph.execute_query(\"\"\"\n",
    "    TODO: Put your query here\n",
    "\"\"\")\n",
    "\n",
    "pandas.DataFrame([dict(r) for r in res.records])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbfb170",
   "metadata": {},
   "source": [
    "## N3\n",
    "\n",
    "- Write and execute a cypher that shows people and movies they both acted in and directed\n",
    "- Your output should have the following attributes:\n",
    "    - `name`, which is the name of the person\n",
    "    - `acted_in_and_directed_movies`, which is an array of titles of movies that the person both acted in and directed\n",
    "- Order your output on `name` ascending, and only keep people that have acted in at least one movie that they directed (i.e., there should be no empty arrays. Arrays with one element are fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = graph.execute_query(\"\"\"\n",
    "    TODO: Put your query here\n",
    "\"\"\")\n",
    "\n",
    "pandas.DataFrame([dict(r) for r in res.records])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0606600",
   "metadata": {},
   "source": [
    "## N4\n",
    "\n",
    "- Write and execute a cypher that shows pairs of people and how closely connected they are\n",
    "- Your output should have the following attributes:\n",
    "    - `person_1_name`, which is the name of the first person in the pair\n",
    "    - `person_2_name`, which is the name of the second person in the pair\n",
    "    - `num_people_between`, which is the number of people (including the pair itself) separating the pair. You should use the `shortestPath` function to compute this.\n",
    "- To prevent duplicates in your output, you should only keep rows where `person_1_name < person_2_name`\n",
    "- Order your output on `(person_1_name, person_2_name)`, and only keep rows where `num_people_between > 5`\n",
    "\n",
    "\n",
    "- As an example, you should get the following row in your output:\n",
    "\n",
    "| person_1_name | person_2_name | num_people_between |\n",
    "|---------------|---------------|--------------------|\n",
    "| Billy Crystal | Paul Blythe   | 6                  |\n",
    "\n",
    "- The shortest path between Billy Crystal and Paul Blythe is shown below\n",
    "    - `num_people_between` is 6 because there are 6 nodes marked as `Person` (including Billy's and Paul's nodes)\n",
    "\n",
    "<img src=\"./N4-example.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4497c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = graph.execute_query(\"\"\"\n",
    "    TODO: Put your query here\n",
    "\"\"\")\n",
    "\n",
    "pandas.DataFrame([dict(r) for r in res.records])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1cf6e2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3932f",
   "metadata": {},
   "source": [
    "# SQL To NoSQL\n",
    "\n",
    "- You will move relational data to document and graph databases\n",
    "    - **You will do your modeling in Python. You shouldn't be writing any SQL.**\n",
    "- You will be using the `classicmodels` database for this section. You may want to drop the database and re-run the SQL script (included in the directory) to ensure you have the right data.\n",
    "    - You will be modeling customers and the products they ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d375d168",
   "metadata": {},
   "source": [
    "## MongoDB: Customers\n",
    "\n",
    "- For the document database, you will create two collections: `customers` and `products`\n",
    "- `customers` will contain customer information as well as all the orders they've placed\n",
    "- You will use `customer_orders_all_df` to create your `customers` collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "customer_orders_all <<\n",
    "\n",
    "select\n",
    "    c.customerNumber, c.customerName, c.country, o.orderNumber,\n",
    "    o.orderDate, od.productCode, od.quantityOrdered, od.priceEach\n",
    "from classicmodels.orders o\n",
    "    join classicmodels.customers c using (customerNumber)\n",
    "    join classicmodels.orderdetails od using (orderNumber);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62188819",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_orders_all_df = customer_orders_all.DataFrame()\n",
    "customer_orders_all_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52203a9",
   "metadata": {},
   "source": [
    "- Below is an example of how a customer and their orders are stored in MySQL, and how the document should look like in MongoDB\n",
    "- The document should have the following attributes:\n",
    "    - `customerNumber`\n",
    "    - `customerName`\n",
    "    - `country`\n",
    "    - `orders`, which is a list of objects. Each object represents one order\n",
    "        - `orderNumber`\n",
    "        - `orderDate`\n",
    "        - `orderContents`, which is a list of objects. Each object represents one product in the order\n",
    "            - `productCode`\n",
    "            - `quantityOrdered`\n",
    "            - `priceEach`\n",
    "            \n",
    "\n",
    "**MySQL relation:**\n",
    "\n",
    "|    |   customerNumber | customerName      | country   |   orderNumber | orderDate   | productCode   |   quantityOrdered |   priceEach |\n",
    "|---:|-----------------:|:------------------|:----------|--------------:|:------------|:--------------|------------------:|------------:|\n",
    "|  0 |              103 | Atelier graphique | France    |         10123 | 2003-05-20  | S18_1589      |                26 |      120.71 |\n",
    "|  1 |              103 | Atelier graphique | France    |         10123 | 2003-05-20  | S18_2870      |                46 |      114.84 |\n",
    "|  2 |              103 | Atelier graphique | France    |         10123 | 2003-05-20  | S18_3685      |                34 |      117.26 |\n",
    "|  3 |              103 | Atelier graphique | France    |         10123 | 2003-05-20  | S24_1628      |                50 |       43.27 |\n",
    "|  4 |              103 | Atelier graphique | France    |         10298 | 2004-09-27  | S10_2016      |                39 |      105.86 |\n",
    "|  5 |              103 | Atelier graphique | France    |         10298 | 2004-09-27  | S18_2625      |                32 |       60.57 |\n",
    "|  6 |              103 | Atelier graphique | France    |         10345 | 2004-11-25  | S24_2022      |                43 |       38.98 |\n",
    "\n",
    "\n",
    "\n",
    "**MongoDB document:**\n",
    "\n",
    "```\n",
    "{\n",
    "    customerNumber: 103\n",
    "    customerName: \"Atelier graphique\",\n",
    "    country: \"France\",\n",
    "    orders: [\n",
    "        {\n",
    "            orderNumber: 10123,\n",
    "            orderDate: \"2003-05-20\",\n",
    "            orderContents: [\n",
    "                {\n",
    "                    productCode: \"S18_1589\",\n",
    "                    quantityOrdered: 26,\n",
    "                    priceEach: \"120.71\"\n",
    "                },\n",
    "                {\n",
    "                    productCode: \"S18_2870\",\n",
    "                    quantityOrdered: 46,\n",
    "                    priceEach: \"114.84\"\n",
    "                },\n",
    "                {\n",
    "                    productCode: \"S18_3685\",\n",
    "                    quantityOrdered: 34,\n",
    "                    priceEach: \"117.26\"\n",
    "                },\n",
    "                {\n",
    "                    productCode: \"S24_1628\",\n",
    "                    quantityOrdered: 50,\n",
    "                    priceEach: \"43.27\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            orderNumber: 10298,\n",
    "            orderDate: \"2004-09-27\",\n",
    "            orderContents: [\n",
    "                {\n",
    "                    productCode: \"S10_2016\",\n",
    "                    quantityOrdered: 39,\n",
    "                    priceEach: \"105.86\"\n",
    "                },\n",
    "                {\n",
    "                    productCode: \"S18_2625\",\n",
    "                    quantityOrdered: 32,\n",
    "                    priceEach: \"60.57\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            orderNumber: 10345,\n",
    "            orderDate: \"2004-11-25\",\n",
    "            orderContents: [\n",
    "                {\n",
    "                    productCode: \"S24_2022\",\n",
    "                    quantityOrdered: 43,\n",
    "                    priceEach: \"38.98\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a list of dicts. Each dict represents one customer.\n",
    "\n",
    "\"\"\"\n",
    "Tips:\n",
    "\n",
    "    To iterate through dataframe:\n",
    "    \n",
    "        for _, r in customer_orders_all_df.iterrows():\n",
    "            r = dict(r)\n",
    "            Access fields like r['customerName'], r['country'], ...\n",
    "            \n",
    "    \n",
    "    The orderDate and priceEach fields are stored as datetime.date and Decimal\n",
    "    objects in the dataframe. These types are not compatible with the pymongo API.\n",
    "    You can convert them to strings by calling str(r['orderDate']) and str(r['priceEach']). \n",
    "    Alternatively, you can look into the datetime.datetime and bson.decimal128.Decimal128 \n",
    "    objects, which are supported by pymongo.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23834a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_customers(d):\n",
    "    mongo_client['w4111']['customers'].drop()\n",
    "    mongo_client['w4111']['customers'].insert_many(d)\n",
    "    \n",
    "\n",
    "# TODO: Put the name of your list of dicts below\n",
    "insert_customers(your_list_of_customers)\n",
    "print(\"Successfully inserted customer data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a2bdc",
   "metadata": {},
   "source": [
    "## MongoDB: Products\n",
    "\n",
    "- To create the `products` collection, you will use `products_all_df`\n",
    "- A document in `products` simply contains product information, as shown below\n",
    "\n",
    "```\n",
    "{\n",
    "    productCode: \"S10_1678\",\n",
    "    productName: \"1969 Harley Davidson Ultimate Chopper\",\n",
    "    productVendor: \"Min Lin Diecast\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "products_all <<\n",
    "\n",
    "select productCode, productName, productVendor\n",
    "from classicmodels.products;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c23b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_all_df = products_all.DataFrame()\n",
    "products_all_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a list of dicts. Each dict represents one product.\n",
    "\n",
    "\"\"\"\n",
    "Tips:\n",
    "\n",
    "    To iterate through dataframe:\n",
    "    \n",
    "        for _, r in products_all_df.iterrows():\n",
    "            r = dict(r)\n",
    "            Access fields like r['productName'], r['productVendor'], ...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_products(d):\n",
    "    mongo_client['w4111']['products'].drop()\n",
    "    mongo_client['w4111']['products'].insert_many(d)\n",
    "    \n",
    "\n",
    "# TODO: Put the name of your list of dicts below\n",
    "insert_products(your_list_of_products)\n",
    "print(\"Successfully inserted product data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555163f8",
   "metadata": {},
   "source": [
    "## MongoDB: Testing\n",
    "\n",
    "- Run through the following cells\n",
    "- **Make sure the outputs are completely visible. You shouldn't need to scroll to see the entire output.**\n",
    "    - You may need to click on the blank section immediately to the left of your output to toggle between scrolling and unscrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def prepr(doc):\n",
    "    try:\n",
    "        del doc['_id']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    def convert_str(d):\n",
    "        if isinstance(d, dict):\n",
    "            for k, v in d.items():\n",
    "                d[k] = convert_str(v)\n",
    "            return d\n",
    "        elif isinstance(d, list):\n",
    "            for i, v in enumerate(d):\n",
    "                d[i] = convert_str(v)\n",
    "            return d\n",
    "        else:\n",
    "            return str(d)\n",
    "                \n",
    "    convert_str(doc)\n",
    "    return json.dumps(doc, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mongo_client['w4111']['customers'].aggregate([\n",
    "    {\n",
    "        '$match': {\n",
    "            'customerNumber': 219\n",
    "        }\n",
    "    }\n",
    "])\n",
    "\n",
    "print(prepr(list(res)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6fde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mongo_client['w4111']['customers'].aggregate([\n",
    "    {\n",
    "        '$match': {\n",
    "            'customerNumber': 103\n",
    "        }\n",
    "    }\n",
    "])\n",
    "\n",
    "print(prepr(list(res)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a19e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mongo_client['w4111']['products'].aggregate([\n",
    "    {\n",
    "        '$match': {\n",
    "            'productCode': 'S18_1889'\n",
    "        }\n",
    "    }\n",
    "])\n",
    "\n",
    "print(prepr(list(res)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fffc7d",
   "metadata": {},
   "source": [
    "## Neo4j: All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0101f",
   "metadata": {},
   "source": [
    "- For the graph database, you will have two types of nodes: `Customer` and `Product`\n",
    "    - **Make sure to use these exact names**\n",
    "- An order is represented as a relationship from the `Customer` node to the `Product` node. The type of the relationship should be `ORDERED`.\n",
    "\n",
    "\n",
    "- You will use `customer_orders_limit_df` to create your graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "customer_orders_limit <<\n",
    "\n",
    "select\n",
    "    c.customerNumber, c.customerName, c.country, o.orderNumber,\n",
    "    o.orderDate, od.productCode, p.productName, p.productVendor,\n",
    "    od.quantityOrdered, od.priceEach\n",
    "from classicmodels.orders o\n",
    "    join classicmodels.customers c using (customerNumber)\n",
    "    join classicmodels.orderdetails od using (orderNumber)\n",
    "    join classicmodels.products p using (productCode)\n",
    "where od.quantityOrdered > 49;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b678eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_orders_limit_df = customer_orders_limit.DataFrame()\n",
    "customer_orders_limit_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d2dfa",
   "metadata": {},
   "source": [
    "- Below is an example of how a customer and their orders are stored in MySQL, and how the graph should look like in Neo4j\n",
    "    - Note that the same order may be represented as many relationships since one order could contain many products\n",
    "- The `Customer` nodes should have the following attributes:\n",
    "    - `customerNumber`\n",
    "    - `customerName`\n",
    "    - `country`\n",
    "- The `Product` nodes should have the following attributes:\n",
    "    - `productCode`\n",
    "    - `productName`\n",
    "    - `productVendor`\n",
    "- The `ORDERED` relationships should have the following attributes:\n",
    "    - `orderNumber`\n",
    "    - `orderDate`\n",
    "    - `quantityOrdered`\n",
    "    - `priceEach`\n",
    "\n",
    "\n",
    "**MySQL relation:**\n",
    "\n",
    "|    |   customerNumber | customerName              | country   |   orderNumber | orderDate   | productCode   | productName                             | productVendor             |   quantityOrdered |   priceEach |\n",
    "|---:|-----------------:|:--------------------------|:----------|--------------:|:------------|:--------------|:----------------------------------------|:--------------------------|------------------:|------------:|\n",
    "|  0 |              450 | The Sharp Gifts Warehouse | USA       |         10250 | 2004-05-11  | S32_4289      | 1928 Ford Phaeton Deluxe                | Highway 66 Mini Classics  |                50 |       62.6  |\n",
    "|  1 |              450 | The Sharp Gifts Warehouse | USA       |         10257 | 2004-06-14  | S18_2949      | 1913 Ford Model T Speedster             | Carousel DieCast Legends  |                50 |       92.19 |\n",
    "|  2 |              450 | The Sharp Gifts Warehouse | USA       |         10400 | 2005-04-01  | S10_4757      | 1972 Alfa Romeo GTA                     | Motor City Art Classics   |                64 |      134.64 |\n",
    "|  3 |              450 | The Sharp Gifts Warehouse | USA       |         10400 | 2005-04-01  | S18_3856      | 1941 Chevrolet Special Deluxe Cabriolet | Exoto Designs             |                58 |       88.93 |\n",
    "|  4 |              450 | The Sharp Gifts Warehouse | USA       |         10407 | 2005-04-22  | S18_1589      | 1965 Aston Martin DB5                   | Classic Metal Creations   |                59 |      114.48 |\n",
    "|  5 |              450 | The Sharp Gifts Warehouse | USA       |         10407 | 2005-04-22  | S18_1749      | 1917 Grand Touring Sedan                | Welly Diecast Productions |                76 |      141.1  |\n",
    "|  6 |              450 | The Sharp Gifts Warehouse | USA       |         10407 | 2005-04-22  | S18_4933      | 1957 Ford Thunderbird                   | Studio M Art Models       |                66 |       64.14 |\n",
    "|  7 |              450 | The Sharp Gifts Warehouse | USA       |         10407 | 2005-04-22  | S24_1628      | 1966 Shelby Cobra 427 S/C               | Carousel DieCast Legends  |                64 |       45.78 |\n",
    "|  8 |              450 | The Sharp Gifts Warehouse | USA       |         10407 | 2005-04-22  | S24_2766      | 1949 Jaguar XK 120                      | Classic Metal Creations   |                76 |       81.78 |\n",
    "|  9 |              450 | The Sharp Gifts Warehouse | USA       |         10407 | 2005-04-22  | S24_2887      | 1952 Citroen-15CV                       | Exoto Designs             |                59 |       98.65 |\n",
    "\n",
    "\n",
    "**Neo4j graph:**\n",
    "\n",
    "<img src=\"./Neo4j-example.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c992b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes all customers and products (and their relationships). \n",
    "# Feel free to run this as many times as you want to reset your data.\n",
    "_ = graph.execute_query(\"\"\"\n",
    "    match (c:Customer), (p:Product)\n",
    "    detach delete c, p\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782185a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write and execute queries to create nodes and relationships\n",
    "\n",
    "\"\"\"\n",
    "Tips:\n",
    "\n",
    "    To iterate through dataframe:\n",
    "    \n",
    "        for _, r in customer_orders_limit_df.iterrows():\n",
    "            r = dict(r)\n",
    "            Access fields like r['customerName'], r['country'], ...\n",
    "            \n",
    "    \n",
    "    The priceEach field are stored as a Decimal object in the dataframe. This type is not \n",
    "    compatible with the neo4j API. You can convert it to a string by calling str(r['priceEach']). \n",
    "\n",
    "\n",
    "    You should call graph.execute_query to execute your queries. This method takes in a second\n",
    "    optional argument, a dict. This allows you to do query parameters. For instance, to execute\n",
    "    the query in the screenshot above, you could run\n",
    "    \n",
    "        graph.execute_query(\n",
    "            \"match (c:Customer { customerNumber: $custNum })-[:ORDERED]->(p:Product) return c, p\",\n",
    "            { \"custNum\": 450 }\n",
    "        )\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616c2ac4",
   "metadata": {},
   "source": [
    "## Neo4j: Testing\n",
    "\n",
    "- Run through the following cells\n",
    "- **Make sure the outputs are fully visible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b91676",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for r in graph.execute_query(\"\"\"\n",
    "    match (c:Customer { customerNumber: 412 })-[o:ORDERED]->(p:Product)\n",
    "    return c, o, p\n",
    "\"\"\").records:\n",
    "    res.append(dict(r['c']) | dict(r['o']) | dict(r['p']))\n",
    "    \n",
    "pandas.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5681c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for r in graph.execute_query(\"\"\"\n",
    "    match (c:Customer)-[o:ORDERED]->(p:Product { productCode: 'S12_2823' })\n",
    "    return c, o, p\n",
    "\"\"\").records:\n",
    "    res.append(dict(r['c']) | dict(r['o']) | dict(r['p']))\n",
    "    \n",
    "pandas.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586422e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for r in graph.execute_query(\"\"\"\n",
    "    match (c:Customer)-[o:ORDERED { quantityOrdered: 60 }]->(p:Product)\n",
    "    return c, o, p\n",
    "\"\"\").records:\n",
    "    res.append(dict(r['c']) | dict(r['o']) | dict(r['p']))\n",
    "    \n",
    "pandas.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ff7db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
